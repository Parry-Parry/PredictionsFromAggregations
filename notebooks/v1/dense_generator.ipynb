{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import logging\n",
    "from pathlib import Path, PurePath\n",
    "from collections import defaultdict\n",
    "\n",
    "from src.models.structures import *\n",
    "from src.models.layers.custom_layers import convnet\n",
    "from src.models.intermediate_robust_generator.model import *\n",
    "from src.models.lstm_based.helper import retrieve_dataset, aggregate\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as tfk\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "import sklearn as sk\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER = 2048\n",
    "BATCH_SIZE = 16\n",
    "LEARNING_RATE = 0.0001\n",
    "EPOCHS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_GEN = 3\n",
    "DATA_PATH = \"\"\n",
    "DATASET = 'MNIST'\n",
    "PARTITIONS = 1000\n",
    "PARTITION_DIR = \"D:\\SUMMER_2022\\PROJECT\\PredictionsFromAggregations\\data\\interim\\lstm\"\n",
    "MODEL_STORE = \"D:\\SUMMER_2022\\PROJECT\\PredictionsFromAggregations\\models\\v1\"\n",
    "SEED = 8008"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name, data = retrieve_dataset(DATASET, None)\n",
    "x_train, x_test, y_train, y_test = data\n",
    "dataset = Dataset(name, x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean, shape, dataset = aggregate(dataset, PARTITIONS, PARTITION_DIR, SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(shape) == 3:\n",
    "    a, b, c = shape\n",
    "    d = 1\n",
    "else:\n",
    "    a, b, c, d = shape\n",
    "\n",
    "n_classes = len(np.unique(dataset.y_train))\n",
    "\n",
    "\n",
    "if len(dataset.x_train.shape) == 3:\n",
    "    x_train = np.expand_dims(dataset.x_train, axis=-1)\n",
    "    x_test = np.expand_dims(dataset.x_test, axis=-1)\n",
    "else:\n",
    "    x_train = dataset.x_train\n",
    "    x_test = dataset.x_test\n",
    "y_train = tfk.utils.to_categorical(dataset.y_train, n_classes)\n",
    "y_test = tfk.utils.to_categorical(dataset.y_test, n_classes)\n",
    "\n",
    "x_train, x_val, y_train, y_val = sk.model_selection.train_test_split(x_train, y_train, test_size=0.1, random_state=42)\n",
    "\"\"\"I present the current worst function in the codebase\"\"\"\n",
    "tf_convert = lambda x, y, types : (tf.data.Dataset.from_tensor_slices((tf.cast(x, types[0]), tf.cast(y, types[1])))).shuffle(BUFFER).batch(BATCH_SIZE, drop_remainder=True).cache().prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "train_set = tf_convert(x_train, y_train, [tf.float32, tf.uint8])\n",
    "test_set = tf_convert(x_test, y_test, [tf.float32, tf.uint8])\n",
    "val_set = tf_convert(x_val, y_val, [tf.float32, tf.uint8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28, 1)\n",
      "(28, 28, 1)\n",
      "(28, 28, 1)\n",
      "(28, 28, 1)\n",
      "(28, 28, 1)\n",
      "(28, 28, 1)\n",
      "(28, 28, 1)\n",
      "(28, 28, 1)\n",
      "(28, 28, 1)\n",
      "(28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "intermediate = convnet\n",
    "config = generator_config((BATCH_SIZE, b, c, d), 10, n_classes, 4, intermediate, None)\n",
    "\n",
    "model = generator_model(config)\n",
    "\n",
    "optim = tfk.optimizers.Adam(learning_rate=0.0001)\n",
    "loss_fn = distance_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model for 1 epochs\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Missing required positional argument",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\SUMMER_2022\\PROJECT\\PredictionsFromAggregations\\notebooks\\v1\\dense_generator.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/SUMMER_2022/PROJECT/PredictionsFromAggregations/notebooks/v1/dense_generator.ipynb#ch0000007?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mTraining Model for \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m epochs\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(EPOCHS))\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/SUMMER_2022/PROJECT/PredictionsFromAggregations/notebooks/v1/dense_generator.ipynb#ch0000007?line=2'>3</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39moptim, loss\u001b[39m=\u001b[39mloss_fn, metrics\u001b[39m=\u001b[39m[tfk\u001b[39m.\u001b[39;49mmetrics\u001b[39m.\u001b[39;49mcategorical_accuracy()])\n",
      "File \u001b[1;32md:\\CONDA\\envs\\tfproba\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m    154\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32md:\\CONDA\\envs\\tfproba\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1076\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1074\u001b[0m \u001b[39mif\u001b[39;00m iterable_params \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1075\u001b[0m   args, kwargs \u001b[39m=\u001b[39m replace_iterable_params(args, kwargs, iterable_params)\n\u001b[1;32m-> 1076\u001b[0m result \u001b[39m=\u001b[39m api_dispatcher\u001b[39m.\u001b[39;49mDispatch(args, kwargs)\n\u001b[0;32m   1077\u001b[0m \u001b[39mif\u001b[39;00m result \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNotImplemented\u001b[39m:\n\u001b[0;32m   1078\u001b[0m   \u001b[39mreturn\u001b[39;00m result\n",
      "\u001b[1;31mTypeError\u001b[0m: Missing required positional argument"
     ]
    }
   ],
   "source": [
    "print('Training Model for {} epochs'.format(EPOCHS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model for 1 epochs\n",
      "Epoch 0...\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 28, 28, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='input_11'), name='input_11', description=\"created by layer 'input_11'\"), but it was called on an input with incompatible shape (16, 28, 28, 784).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer \"generator0\" (type generator_block).\n\nin user code:\n\n    File \"d:\\CONDA\\envs\\tfproba\\lib\\site-packages\\src-0.1.0-py3.9.egg\\src\\models\\layers\\custom_layers.py\", line 47, in call  *\n        if self.intermediate: x = self.intermediate(x)\n    File \"d:\\CONDA\\envs\\tfproba\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n    File \"d:\\CONDA\\envs\\tfproba\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 248, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer \"sequential_10\" (type Sequential).\n    \n    Input 0 of layer \"conv2d_40\" is incompatible with the layer: expected axis -1 of input shape to have value 1, but received input with shape (16, 28, 28, 784)\n    \n    Call arguments received by layer \"sequential_10\" (type Sequential):\n      • inputs=tf.Tensor(shape=(16, 28, 28, 784), dtype=float32)\n      • training=True\n      • mask=None\n\n\nCall arguments received by layer \"generator0\" (type generator_block):\n  • input_tensor=tf.Tensor(shape=(16, 28, 28, 1), dtype=float32)\n  • training=True",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\SUMMER_2022\\PROJECT\\PredictionsFromAggregations\\notebooks\\v1\\dense_generator.ipynb Cell 9\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/SUMMER_2022/PROJECT/PredictionsFromAggregations/notebooks/v1/dense_generator.ipynb#ch0000008?line=9'>10</a>\u001b[0m \u001b[39mfor\u001b[39;00m step, (x_batch, y_batch) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_set): \n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/SUMMER_2022/PROJECT/PredictionsFromAggregations/notebooks/v1/dense_generator.ipynb#ch0000008?line=10'>11</a>\u001b[0m     \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mGradientTape() \u001b[39mas\u001b[39;00m tape:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/SUMMER_2022/PROJECT/PredictionsFromAggregations/notebooks/v1/dense_generator.ipynb#ch0000008?line=11'>12</a>\u001b[0m         pred, preds \u001b[39m=\u001b[39m model(x_batch, training\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/SUMMER_2022/PROJECT/PredictionsFromAggregations/notebooks/v1/dense_generator.ipynb#ch0000008?line=12'>13</a>\u001b[0m         weights \u001b[39m=\u001b[39m [generator\u001b[39m.\u001b[39mget_layer(\u001b[39m\"\u001b[39m\u001b[39mgenerator_dense\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mweights \u001b[39mfor\u001b[39;00m generator \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mgenerators]\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/SUMMER_2022/PROJECT/PredictionsFromAggregations/notebooks/v1/dense_generator.ipynb#ch0000008?line=13'>14</a>\u001b[0m         loss_value \u001b[39m=\u001b[39m loss_fn(y_batch, weights, preds)\n",
      "File \u001b[1;32md:\\CONDA\\envs\\tfproba\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32md:\\CONDA\\envs\\tfproba\\lib\\site-packages\\src-0.1.0-py3.9.egg\\src\\models\\intermediate_robust_generator\\model.py:33\u001b[0m, in \u001b[0;36mgenerator_model.call\u001b[1;34m(self, input_tensor, training)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcall\u001b[39m(\u001b[39mself\u001b[39m, input_tensor, training\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m---> 33\u001b[0m     intermediate \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mstack([gen(input_tensor, training) \u001b[39mfor\u001b[39;00m gen \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgenerators], axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m     34\u001b[0m     \u001b[39mif\u001b[39;00m training: \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_max_proba(intermediate), intermediate \n\u001b[0;32m     35\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_max_proba(intermediate)\n",
      "File \u001b[1;32md:\\CONDA\\envs\\tfproba\\lib\\site-packages\\src-0.1.0-py3.9.egg\\src\\models\\intermediate_robust_generator\\model.py:33\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcall\u001b[39m(\u001b[39mself\u001b[39m, input_tensor, training\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m---> 33\u001b[0m     intermediate \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mstack([gen(input_tensor, training) \u001b[39mfor\u001b[39;00m gen \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgenerators], axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m     34\u001b[0m     \u001b[39mif\u001b[39;00m training: \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_max_proba(intermediate), intermediate \n\u001b[0;32m     35\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_max_proba(intermediate)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filejce0yuay.py:42\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[1;34m(self, input_tensor, training)\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[39mnonlocal\u001b[39;00m x\n\u001b[0;32m     41\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m ag__\u001b[39m.\u001b[39mif_stmt(ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mintermediate, if_body_1, else_body_1, get_state_1, set_state_1, (\u001b[39m'\u001b[39m\u001b[39mx\u001b[39m\u001b[39m'\u001b[39m,), \u001b[39m1\u001b[39m)\n\u001b[0;32m     43\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     44\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filejce0yuay.py:37\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call.<locals>.if_body_1\u001b[1;34m()\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mif_body_1\u001b[39m():\n\u001b[0;32m     36\u001b[0m     \u001b[39mnonlocal\u001b[39;00m x\n\u001b[1;32m---> 37\u001b[0m     x \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(\u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mintermediate, (ag__\u001b[39m.\u001b[39;49mld(x),), \u001b[39mNone\u001b[39;49;00m, fscope)\n",
      "\u001b[1;31mValueError\u001b[0m: Exception encountered when calling layer \"generator0\" (type generator_block).\n\nin user code:\n\n    File \"d:\\CONDA\\envs\\tfproba\\lib\\site-packages\\src-0.1.0-py3.9.egg\\src\\models\\layers\\custom_layers.py\", line 47, in call  *\n        if self.intermediate: x = self.intermediate(x)\n    File \"d:\\CONDA\\envs\\tfproba\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n    File \"d:\\CONDA\\envs\\tfproba\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 248, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer \"sequential_10\" (type Sequential).\n    \n    Input 0 of layer \"conv2d_40\" is incompatible with the layer: expected axis -1 of input shape to have value 1, but received input with shape (16, 28, 28, 784)\n    \n    Call arguments received by layer \"sequential_10\" (type Sequential):\n      • inputs=tf.Tensor(shape=(16, 28, 28, 784), dtype=float32)\n      • training=True\n      • mask=None\n\n\nCall arguments received by layer \"generator0\" (type generator_block):\n  • input_tensor=tf.Tensor(shape=(16, 28, 28, 1), dtype=float32)\n  • training=True"
     ]
    }
   ],
   "source": [
    "print('Training Model for {} epochs'.format(EPOCHS))\n",
    "\n",
    "train_acc_store = defaultdict(list)\n",
    "history = defaultdict(list)\n",
    "\n",
    "train_acc_metric = tfk.metrics.CategoricalAccuracy()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print('Epoch {}...'.format(epoch))\n",
    "    for step, (x_batch, y_batch) in enumerate(train_set): \n",
    "        with tf.GradientTape() as tape:\n",
    "            pred, preds = model(x_batch, training=True)\n",
    "            weights = [generator.get_layer(\"generator_dense\").weights for generator in model.generators]\n",
    "            loss_value = loss_fn(y_batch, weights, preds)\n",
    "        history[epoch].append(loss_value)\n",
    "        grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "        optim.apply_gradients(zip(grads, model.trainable_weights))\n",
    "\n",
    "        train_acc_metric.update_state(y_batch, pred)\n",
    "\n",
    "    train_acc = train_acc_metric.result()\n",
    "    train_acc_store[epoch].append(train_acc)\n",
    "    print(\"Training acc over epoch: {}, loss: {}\".format(float(train_acc), float(loss_value)))\n",
    "\n",
    "    train_acc_metric.reset_states()\n",
    "\n",
    "test_acc_metric = tfk.metrics.CategoricalAccuracy()\n",
    "\n",
    "for x_batch, y_batch in test_set:\n",
    "    test_pred = model(x_batch, training=False)\n",
    "    test_acc_metric.update_state(y_batch, test_pred)\n",
    "test_acc = test_acc_metric.result()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('tfproba')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "436b4fcf59259da6dc58e7cba2c0763a6ef61d3e8a386de76ee8b72546013833"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
