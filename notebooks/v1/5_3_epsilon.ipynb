{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import logging\n",
    "from pathlib import Path, PurePath\n",
    "from collections import defaultdict\n",
    "from src.models.lstm_based.base_model import epsilon_3_model, epsilon_5_model\n",
    "\n",
    "from src.models.structures import *\n",
    "from src.models.intermediate_robust_generator.model import *\n",
    "from src.models.lstm_based.helper import retrieve_dataset, aggregate\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as tfk\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "import sklearn as sk\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER = 2048\n",
    "BATCH_SIZE = 128\n",
    "LEARNING_RATE = 0.0001\n",
    "EPOCHS = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_GEN = 3\n",
    "DATA_PATH = \"\"\n",
    "DATASET = 'MNIST'\n",
    "PARTITIONS = 1000\n",
    "PARTITION_DIR = \"D:\\SUMMER_2022\\PROJECT\\PredictionsFromAggregations\\data\\interim\\lstm\"\n",
    "MODEL_STORE = \"D:\\SUMMER_2022\\PROJECT\\PredictionsFromAggregations\\models\\v1\"\n",
    "SEED = 8008"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "name, data = retrieve_dataset(DATASET, None)\n",
    "x_train, x_test, y_train, y_test = data\n",
    "dataset = Dataset(name, x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean, shape, dataset = aggregate(dataset, PARTITIONS, PARTITION_DIR, SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(shape) == 3:\n",
    "    a, b, c = shape\n",
    "    d = 1\n",
    "else:\n",
    "    a, b, c, d = shape\n",
    "\n",
    "n_classes = len(np.unique(dataset.y_train))\n",
    "\n",
    "\n",
    "if len(dataset.x_train.shape) == 3:\n",
    "    x_train = np.expand_dims(dataset.x_train, axis=-1)\n",
    "    x_test = np.expand_dims(dataset.x_test, axis=-1)\n",
    "else:\n",
    "    x_train = dataset.x_train\n",
    "    x_test = dataset.x_test\n",
    "y_train = tfk.utils.to_categorical(dataset.y_train, n_classes)\n",
    "y_test = tfk.utils.to_categorical(dataset.y_test, n_classes)\n",
    "\n",
    "x_train, x_val, y_train, y_val = sk.model_selection.train_test_split(x_train, y_train, test_size=0.1, random_state=42)\n",
    "\"\"\"I present the current worst function in the codebase\"\"\"\n",
    "tf_convert = lambda x, y, types : (tf.data.Dataset.from_tensor_slices((tf.cast(x, types[0]), tf.cast(y, types[1])))).shuffle(BUFFER).batch(BATCH_SIZE, drop_remainder=True).cache().prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "train_set = tf_convert(x_train, y_train, [tf.float32, tf.uint8])\n",
    "test_set = tf_convert(x_test, y_test, [tf.float32, tf.uint8])\n",
    "val_set = tf_convert(x_val, y_val, [tf.float32, tf.uint8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = generator_config(b*c*d, 10, n_classes, 4, None, None)\n",
    "models ={\n",
    "    3 : epsilon_3_model,\n",
    "    5 : epsilon_5_model\n",
    "}\n",
    "try:\n",
    "    model = models[N_GEN](config)\n",
    "except KeyError:\n",
    "    print(\"No model matched n_gen value: {}\".format(N_GEN))\n",
    "    exit\n",
    "\n",
    "optim = tfk.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
    "loss_fn = tfk.losses.CategoricalCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model for 15 epochs\n",
      "Epoch 0...\n",
      "ERROR:tensorflow:==================================\n",
      "Object was never used (type <class 'tensorflow.python.ops.tensor_array_ops.TensorArray'>):\n",
      "<tensorflow.python.ops.tensor_array_ops.TensorArray object at 0x0000021266252CD0>\n",
      "If you want to mark it as used call its \"mark_used()\" method.\n",
      "It was originally created here:\n",
      "  File \"d:\\CONDA\\envs\\tfproba\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\", line 2789, in while_loop\n",
      "    return result  File \"d:\\CONDA\\envs\\tfproba\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\", line 2745, in <lambda>\n",
      "    body = lambda i, lv: (i + 1, orig_body(*lv))  File \"d:\\CONDA\\envs\\tfproba\\lib\\site-packages\\tensorflow\\python\\ops\\map_fn.py\", line 493, in compute\n",
      "    return (i + 1, tas)  File \"d:\\CONDA\\envs\\tfproba\\lib\\site-packages\\tensorflow\\python\\ops\\map_fn.py\", line 491, in <listcomp>\n",
      "    ta.write(i, value) for (ta, value) in zip(tas, result_value_batchable)  File \"d:\\CONDA\\envs\\tfproba\\lib\\site-packages\\tensorflow\\python\\util\\tf_should_use.py\", line 243, in wrapped\n",
      "    return _add_should_use_warning(fn(*args, **kwargs),\n",
      "==================================\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\SUMMER_2022\\PROJECT\\PredictionsFromAggregations\\notebooks\\v1\\5_3_epsilon.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/SUMMER_2022/PROJECT/PredictionsFromAggregations/notebooks/v1/5_3_epsilon.ipynb#ch0000007?line=9'>10</a>\u001b[0m \u001b[39mfor\u001b[39;00m step, (x_batch, y_batch) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_set): \n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/SUMMER_2022/PROJECT/PredictionsFromAggregations/notebooks/v1/5_3_epsilon.ipynb#ch0000007?line=10'>11</a>\u001b[0m     \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mGradientTape() \u001b[39mas\u001b[39;00m tape:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/SUMMER_2022/PROJECT/PredictionsFromAggregations/notebooks/v1/5_3_epsilon.ipynb#ch0000007?line=11'>12</a>\u001b[0m         pred \u001b[39m=\u001b[39m model(x_batch)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/SUMMER_2022/PROJECT/PredictionsFromAggregations/notebooks/v1/5_3_epsilon.ipynb#ch0000007?line=12'>13</a>\u001b[0m         loss_value \u001b[39m=\u001b[39m loss_fn(y_batch, pred)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/SUMMER_2022/PROJECT/PredictionsFromAggregations/notebooks/v1/5_3_epsilon.ipynb#ch0000007?line=13'>14</a>\u001b[0m     results\u001b[39m.\u001b[39mhistory[epoch]\u001b[39m.\u001b[39mappend(loss_value)\n",
      "File \u001b[1;32md:\\CONDA\\envs\\tfproba\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32md:\\CONDA\\envs\\tfproba\\lib\\site-packages\\keras\\engine\\training.py:490\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    486\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m(inputs, \u001b[39m*\u001b[39mcopied_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcopied_kwargs)\n\u001b[0;32m    488\u001b[0m   layout_map_lib\u001b[39m.\u001b[39m_map_subclass_model_variable(\u001b[39mself\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_layout_map)\n\u001b[1;32m--> 490\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\CONDA\\envs\\tfproba\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32md:\\CONDA\\envs\\tfproba\\lib\\site-packages\\keras\\engine\\base_layer.py:1014\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1010\u001b[0m   inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[0;32m   1012\u001b[0m \u001b[39mwith\u001b[39;00m autocast_variable\u001b[39m.\u001b[39menable_auto_cast_variables(\n\u001b[0;32m   1013\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_dtype_object):\n\u001b[1;32m-> 1014\u001b[0m   outputs \u001b[39m=\u001b[39m call_fn(inputs, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1016\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_activity_regularizer:\n\u001b[0;32m   1017\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[1;32md:\\CONDA\\envs\\tfproba\\lib\\site-packages\\keras\\utils\\traceback_utils.py:92\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     90\u001b[0m bound_signature \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     91\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 92\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     93\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     94\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m'\u001b[39m\u001b[39m_keras_call_info_injected\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m     95\u001b[0m     \u001b[39m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[1;32md:\\CONDA\\envs\\tfproba\\lib\\site-packages\\src-0.1.0-py3.9.egg\\src\\models\\lstm_based\\base_model.py:46\u001b[0m, in \u001b[0;36mepsilon_3_model.call\u001b[1;34m(self, input_tensor)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcall\u001b[39m(\u001b[39mself\u001b[39m, input_tensor):\n\u001b[1;32m---> 46\u001b[0m     gen1 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerator1(input_tensor)\n\u001b[0;32m     47\u001b[0m     gen2 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgenerator2(input_tensor)\n\u001b[0;32m     48\u001b[0m     gen3 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgenerator3(input_tensor)\n",
      "File \u001b[1;32md:\\CONDA\\envs\\tfproba\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32md:\\CONDA\\envs\\tfproba\\lib\\site-packages\\keras\\engine\\base_layer.py:1014\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1010\u001b[0m   inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[0;32m   1012\u001b[0m \u001b[39mwith\u001b[39;00m autocast_variable\u001b[39m.\u001b[39menable_auto_cast_variables(\n\u001b[0;32m   1013\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_dtype_object):\n\u001b[1;32m-> 1014\u001b[0m   outputs \u001b[39m=\u001b[39m call_fn(inputs, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1016\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_activity_regularizer:\n\u001b[0;32m   1017\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[1;32md:\\CONDA\\envs\\tfproba\\lib\\site-packages\\keras\\utils\\traceback_utils.py:92\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     90\u001b[0m bound_signature \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     91\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 92\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     93\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     94\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m'\u001b[39m\u001b[39m_keras_call_info_injected\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m     95\u001b[0m     \u001b[39m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[1;32md:\\CONDA\\envs\\tfproba\\lib\\site-packages\\src-0.1.0-py3.9.egg\\src\\models\\layers\\custom_layers.py:43\u001b[0m, in \u001b[0;36msingle_epsilon_generator.call\u001b[1;34m(self, input_tensor)\u001b[0m\n\u001b[0;32m     41\u001b[0m a, b, c, d \u001b[39m=\u001b[39m input_tensor\u001b[39m.\u001b[39mshape\n\u001b[0;32m     42\u001b[0m interim_tensor \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mreshape(input_tensor, [\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\n\u001b[1;32m---> 43\u001b[0m x \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mmap_fn(\u001b[39mlambda\u001b[39;49;00m x : \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_distr(x), elems\u001b[39m=\u001b[39;49minterim_tensor)\n\u001b[0;32m     44\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintermediate: \n\u001b[0;32m     45\u001b[0m     x \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mreshape(x, [a, b, c, d])\n",
      "File \u001b[1;32md:\\CONDA\\envs\\tfproba\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:629\u001b[0m, in \u001b[0;36mdeprecated_arg_values.<locals>.deprecated_wrapper.<locals>.new_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    622\u001b[0m           _PRINTED_WARNING[(func, arg_name)] \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    623\u001b[0m         logging\u001b[39m.\u001b[39mwarning(\n\u001b[0;32m    624\u001b[0m             \u001b[39m'\u001b[39m\u001b[39mFrom \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: calling \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m (from \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m) with \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m=\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m is deprecated and \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    625\u001b[0m             \u001b[39m'\u001b[39m\u001b[39mwill be removed \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mInstructions for updating:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m,\n\u001b[0;32m    626\u001b[0m             _call_location(), decorator_utils\u001b[39m.\u001b[39mget_qualified_name(func),\n\u001b[0;32m    627\u001b[0m             func\u001b[39m.\u001b[39m\u001b[39m__module__\u001b[39m, arg_name, arg_value, \u001b[39m'\u001b[39m\u001b[39min a future version\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    628\u001b[0m             \u001b[39mif\u001b[39;00m date \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m (\u001b[39m'\u001b[39m\u001b[39mafter \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m date), instructions)\n\u001b[1;32m--> 629\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\CONDA\\envs\\tfproba\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:561\u001b[0m, in \u001b[0;36mdeprecated_args.<locals>.deprecated_wrapper.<locals>.new_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    553\u001b[0m         _PRINTED_WARNING[(func, arg_name)] \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    554\u001b[0m       logging\u001b[39m.\u001b[39mwarning(\n\u001b[0;32m    555\u001b[0m           \u001b[39m'\u001b[39m\u001b[39mFrom \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: calling \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m (from \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m) with \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m is deprecated and will \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    556\u001b[0m           \u001b[39m'\u001b[39m\u001b[39mbe removed \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mInstructions for updating:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    559\u001b[0m           \u001b[39m'\u001b[39m\u001b[39min a future version\u001b[39m\u001b[39m'\u001b[39m \u001b[39mif\u001b[39;00m date \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m (\u001b[39m'\u001b[39m\u001b[39mafter \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m date),\n\u001b[0;32m    560\u001b[0m           instructions)\n\u001b[1;32m--> 561\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\CONDA\\envs\\tfproba\\lib\\site-packages\\tensorflow\\python\\ops\\map_fn.py:637\u001b[0m, in \u001b[0;36mmap_fn_v2\u001b[1;34m(fn, elems, dtype, parallel_iterations, back_prop, swap_memory, infer_shape, name, fn_output_signature)\u001b[0m\n\u001b[0;32m    635\u001b[0m \u001b[39mif\u001b[39;00m fn_output_signature \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    636\u001b[0m   fn_output_signature \u001b[39m=\u001b[39m dtype\n\u001b[1;32m--> 637\u001b[0m \u001b[39mreturn\u001b[39;00m map_fn(\n\u001b[0;32m    638\u001b[0m     fn\u001b[39m=\u001b[39;49mfn,\n\u001b[0;32m    639\u001b[0m     elems\u001b[39m=\u001b[39;49melems,\n\u001b[0;32m    640\u001b[0m     fn_output_signature\u001b[39m=\u001b[39;49mfn_output_signature,\n\u001b[0;32m    641\u001b[0m     parallel_iterations\u001b[39m=\u001b[39;49mparallel_iterations,\n\u001b[0;32m    642\u001b[0m     back_prop\u001b[39m=\u001b[39;49mback_prop,\n\u001b[0;32m    643\u001b[0m     swap_memory\u001b[39m=\u001b[39;49mswap_memory,\n\u001b[0;32m    644\u001b[0m     infer_shape\u001b[39m=\u001b[39;49minfer_shape,\n\u001b[0;32m    645\u001b[0m     name\u001b[39m=\u001b[39;49mname)\n",
      "File \u001b[1;32md:\\CONDA\\envs\\tfproba\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:561\u001b[0m, in \u001b[0;36mdeprecated_args.<locals>.deprecated_wrapper.<locals>.new_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    553\u001b[0m         _PRINTED_WARNING[(func, arg_name)] \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    554\u001b[0m       logging\u001b[39m.\u001b[39mwarning(\n\u001b[0;32m    555\u001b[0m           \u001b[39m'\u001b[39m\u001b[39mFrom \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: calling \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m (from \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m) with \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m is deprecated and will \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    556\u001b[0m           \u001b[39m'\u001b[39m\u001b[39mbe removed \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mInstructions for updating:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    559\u001b[0m           \u001b[39m'\u001b[39m\u001b[39min a future version\u001b[39m\u001b[39m'\u001b[39m \u001b[39mif\u001b[39;00m date \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m (\u001b[39m'\u001b[39m\u001b[39mafter \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m date),\n\u001b[0;32m    560\u001b[0m           instructions)\n\u001b[1;32m--> 561\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\CONDA\\envs\\tfproba\\lib\\site-packages\\tensorflow\\python\\ops\\map_fn.py:495\u001b[0m, in \u001b[0;36mmap_fn\u001b[1;34m(fn, elems, dtype, parallel_iterations, back_prop, swap_memory, infer_shape, name, fn_output_signature)\u001b[0m\n\u001b[0;32m    490\u001b[0m   tas \u001b[39m=\u001b[39m [\n\u001b[0;32m    491\u001b[0m       ta\u001b[39m.\u001b[39mwrite(i, value) \u001b[39mfor\u001b[39;00m (ta, value) \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(tas, result_value_batchable)\n\u001b[0;32m    492\u001b[0m   ]\n\u001b[0;32m    493\u001b[0m   \u001b[39mreturn\u001b[39;00m (i \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m, tas)\n\u001b[1;32m--> 495\u001b[0m _, r_a \u001b[39m=\u001b[39m control_flow_ops\u001b[39m.\u001b[39;49mwhile_loop(\n\u001b[0;32m    496\u001b[0m     \u001b[39mlambda\u001b[39;49;00m i, _: i \u001b[39m<\u001b[39;49m n,\n\u001b[0;32m    497\u001b[0m     compute, (i, result_batchable_ta),\n\u001b[0;32m    498\u001b[0m     parallel_iterations\u001b[39m=\u001b[39;49mparallel_iterations,\n\u001b[0;32m    499\u001b[0m     back_prop\u001b[39m=\u001b[39;49mback_prop,\n\u001b[0;32m    500\u001b[0m     swap_memory\u001b[39m=\u001b[39;49mswap_memory,\n\u001b[0;32m    501\u001b[0m     maximum_iterations\u001b[39m=\u001b[39;49mn)\n\u001b[0;32m    502\u001b[0m result_batchable \u001b[39m=\u001b[39m [r\u001b[39m.\u001b[39mstack() \u001b[39mfor\u001b[39;00m r \u001b[39min\u001b[39;00m r_a]\n\u001b[0;32m    504\u001b[0m \u001b[39m# Update each output tensor w/ static shape info about the outer dimension.\u001b[39;00m\n",
      "File \u001b[1;32md:\\CONDA\\envs\\tfproba\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py:2754\u001b[0m, in \u001b[0;36mwhile_loop\u001b[1;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\u001b[0m\n\u001b[0;32m   2751\u001b[0m loop_var_structure \u001b[39m=\u001b[39m nest\u001b[39m.\u001b[39mmap_structure(type_spec\u001b[39m.\u001b[39mtype_spec_from_value,\n\u001b[0;32m   2752\u001b[0m                                         \u001b[39mlist\u001b[39m(loop_vars))\n\u001b[0;32m   2753\u001b[0m \u001b[39mwhile\u001b[39;00m cond(\u001b[39m*\u001b[39mloop_vars):\n\u001b[1;32m-> 2754\u001b[0m   loop_vars \u001b[39m=\u001b[39m body(\u001b[39m*\u001b[39;49mloop_vars)\n\u001b[0;32m   2755\u001b[0m   \u001b[39mif\u001b[39;00m try_to_pack \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(loop_vars, (\u001b[39mlist\u001b[39m, _basetuple)):\n\u001b[0;32m   2756\u001b[0m     packed \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32md:\\CONDA\\envs\\tfproba\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py:2745\u001b[0m, in \u001b[0;36mwhile_loop.<locals>.<lambda>\u001b[1;34m(i, lv)\u001b[0m\n\u001b[0;32m   2742\u001b[0m     loop_vars \u001b[39m=\u001b[39m (counter, loop_vars)\n\u001b[0;32m   2743\u001b[0m     cond \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m i, lv: (  \u001b[39m# pylint: disable=g-long-lambda\u001b[39;00m\n\u001b[0;32m   2744\u001b[0m         math_ops\u001b[39m.\u001b[39mlogical_and(i \u001b[39m<\u001b[39m maximum_iterations, orig_cond(\u001b[39m*\u001b[39mlv)))\n\u001b[1;32m-> 2745\u001b[0m     body \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m i, lv: (i \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m, orig_body(\u001b[39m*\u001b[39;49mlv))\n\u001b[0;32m   2746\u001b[0m   try_to_pack \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   2748\u001b[0m \u001b[39mif\u001b[39;00m executing_eagerly:\n",
      "File \u001b[1;32md:\\CONDA\\envs\\tfproba\\lib\\site-packages\\tensorflow\\python\\ops\\map_fn.py:485\u001b[0m, in \u001b[0;36mmap_fn.<locals>.compute\u001b[1;34m(i, tas)\u001b[0m\n\u001b[0;32m    483\u001b[0m ag_ctx \u001b[39m=\u001b[39m autograph_ctx\u001b[39m.\u001b[39mcontrol_status_ctx()\n\u001b[0;32m    484\u001b[0m autographed_fn \u001b[39m=\u001b[39m autograph\u001b[39m.\u001b[39mtf_convert(fn, ag_ctx)\n\u001b[1;32m--> 485\u001b[0m result_value \u001b[39m=\u001b[39m autographed_fn(elems_value)\n\u001b[0;32m    486\u001b[0m nest\u001b[39m.\u001b[39massert_same_structure(fn_output_signature \u001b[39mor\u001b[39;00m elems, result_value)\n\u001b[0;32m    487\u001b[0m result_value_flat \u001b[39m=\u001b[39m nest\u001b[39m.\u001b[39mflatten(result_value)\n",
      "File \u001b[1;32md:\\CONDA\\envs\\tfproba\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:689\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    687\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    688\u001b[0m   \u001b[39mwith\u001b[39;00m conversion_ctx:\n\u001b[1;32m--> 689\u001b[0m     \u001b[39mreturn\u001b[39;00m converted_call(f, args, kwargs, options\u001b[39m=\u001b[39;49moptions)\n\u001b[0;32m    690\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m    691\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m'\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m'\u001b[39m):\n",
      "File \u001b[1;32md:\\CONDA\\envs\\tfproba\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    438\u001b[0m   \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 439\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39meffective_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    440\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    441\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39meffective_args)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filednyr_hid.py:6\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minner_factory\u001b[39m(ag__):\n\u001b[1;32m----> 6\u001b[0m     tf__lam \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m x: ag__\u001b[39m.\u001b[39;49mwith_function_scope(\u001b[39mlambda\u001b[39;49;00m lscope: ag__\u001b[39m.\u001b[39;49mconverted_call(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_distr, (x,), \u001b[39mNone\u001b[39;49;00m, lscope), \u001b[39m'\u001b[39;49m\u001b[39mlscope\u001b[39;49m\u001b[39m'\u001b[39;49m, ag__\u001b[39m.\u001b[39;49mSTD)\n\u001b[0;32m      7\u001b[0m     \u001b[39mreturn\u001b[39;00m tf__lam\n",
      "File \u001b[1;32md:\\CONDA\\envs\\tfproba\\lib\\site-packages\\tensorflow\\python\\autograph\\core\\function_wrappers.py:113\u001b[0m, in \u001b[0;36mwith_function_scope\u001b[1;34m(thunk, scope_name, options)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[39m\"\"\"Inline version of the FunctionScope context manager.\"\"\"\u001b[39;00m\n\u001b[0;32m    112\u001b[0m \u001b[39mwith\u001b[39;00m FunctionScope(\u001b[39m'\u001b[39m\u001b[39mlambda_\u001b[39m\u001b[39m'\u001b[39m, scope_name, options) \u001b[39mas\u001b[39;00m scope:\n\u001b[1;32m--> 113\u001b[0m   \u001b[39mreturn\u001b[39;00m thunk(scope)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filednyr_hid.py:6\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.<lambda>\u001b[1;34m(lscope)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minner_factory\u001b[39m(ag__):\n\u001b[1;32m----> 6\u001b[0m     tf__lam \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m x: ag__\u001b[39m.\u001b[39mwith_function_scope(\u001b[39mlambda\u001b[39;00m lscope: ag__\u001b[39m.\u001b[39;49mconverted_call(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_distr, (x,), \u001b[39mNone\u001b[39;49;00m, lscope), \u001b[39m'\u001b[39m\u001b[39mlscope\u001b[39m\u001b[39m'\u001b[39m, ag__\u001b[39m.\u001b[39mSTD)\n\u001b[0;32m      7\u001b[0m     \u001b[39mreturn\u001b[39;00m tf__lam\n",
      "File \u001b[1;32md:\\CONDA\\envs\\tfproba\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:441\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    439\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39meffective_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    440\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 441\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39;49meffective_args)\n\u001b[0;32m    442\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    443\u001b[0m   _attach_error_metadata(e, converted_f)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filewf2j5lv1.py:12\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf___distr\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m     10\u001b[0m value \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(value)\u001b[39m.\u001b[39mnumpy, (), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m     11\u001b[0m distr \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(tfp)\u001b[39m.\u001b[39mdistributions\u001b[39m.\u001b[39mUniform, (), \u001b[39mdict\u001b[39m(low\u001b[39m=\u001b[39mag__\u001b[39m.\u001b[39mld(value) \u001b[39m-\u001b[39m ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mepsilon, high\u001b[39m=\u001b[39mag__\u001b[39m.\u001b[39mld(value) \u001b[39m+\u001b[39m ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mepsilon), fscope)\n\u001b[1;32m---> 12\u001b[0m x \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(tf)\u001b[39m.\u001b[39mmath\u001b[39m.\u001b[39mminimum, (ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(tf)\u001b[39m.\u001b[39mmath\u001b[39m.\u001b[39mmaximum, (\u001b[39m0.0\u001b[39m, ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(distr)\u001b[39m.\u001b[39;49msample, (), \u001b[39mNone\u001b[39;49;00m, fscope)), \u001b[39mNone\u001b[39;00m, fscope), \u001b[39m1.0\u001b[39m), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32md:\\CONDA\\envs\\tfproba\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:331\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    329\u001b[0m \u001b[39mif\u001b[39;00m conversion\u001b[39m.\u001b[39mis_in_allowlist_cache(f, options):\n\u001b[0;32m    330\u001b[0m   logging\u001b[39m.\u001b[39mlog(\u001b[39m2\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mAllowlisted \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: from cache\u001b[39m\u001b[39m'\u001b[39m, f)\n\u001b[1;32m--> 331\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options, \u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    333\u001b[0m \u001b[39mif\u001b[39;00m ag_ctx\u001b[39m.\u001b[39mcontrol_status_ctx()\u001b[39m.\u001b[39mstatus \u001b[39m==\u001b[39m ag_ctx\u001b[39m.\u001b[39mStatus\u001b[39m.\u001b[39mDISABLED:\n\u001b[0;32m    334\u001b[0m   logging\u001b[39m.\u001b[39mlog(\u001b[39m2\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mAllowlisted: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: AutoGraph is disabled in context\u001b[39m\u001b[39m'\u001b[39m, f)\n",
      "File \u001b[1;32md:\\CONDA\\envs\\tfproba\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:459\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[1;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[0;32m    457\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    458\u001b[0m   \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m--> 459\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs)\n",
      "File \u001b[1;32md:\\CONDA\\envs\\tfproba\\lib\\site-packages\\tensorflow_probability\\python\\distributions\\distribution.py:1234\u001b[0m, in \u001b[0;36mDistribution.sample\u001b[1;34m(self, sample_shape, seed, name, **kwargs)\u001b[0m\n\u001b[0;32m   1219\u001b[0m \u001b[39m\"\"\"Generate samples of the specified shape.\u001b[39;00m\n\u001b[0;32m   1220\u001b[0m \n\u001b[0;32m   1221\u001b[0m \u001b[39mNote that a call to `sample()` without arguments will generate a single\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1231\u001b[0m \u001b[39m  samples: a `Tensor` with prepended dimensions `sample_shape`.\u001b[39;00m\n\u001b[0;32m   1232\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1233\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_name_and_control_scope(name):\n\u001b[1;32m-> 1234\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_sample_n(sample_shape, seed, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\CONDA\\envs\\tfproba\\lib\\site-packages\\tensorflow_probability\\python\\distributions\\distribution.py:1211\u001b[0m, in \u001b[0;36mDistribution._call_sample_n\u001b[1;34m(self, sample_shape, seed, **kwargs)\u001b[0m\n\u001b[0;32m   1207\u001b[0m sample_shape \u001b[39m=\u001b[39m ps\u001b[39m.\u001b[39mconvert_to_shape_tensor(\n\u001b[0;32m   1208\u001b[0m     ps\u001b[39m.\u001b[39mcast(sample_shape, tf\u001b[39m.\u001b[39mint32), name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msample_shape\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m   1209\u001b[0m sample_shape, n \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_expand_sample_shape_to_vector(\n\u001b[0;32m   1210\u001b[0m     sample_shape, \u001b[39m'\u001b[39m\u001b[39msample_shape\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m-> 1211\u001b[0m samples \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sample_n(\n\u001b[0;32m   1212\u001b[0m     n, seed\u001b[39m=\u001b[39mseed() \u001b[39mif\u001b[39;00m callable(seed) \u001b[39melse\u001b[39;00m seed, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1213\u001b[0m samples \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mmap_structure(\n\u001b[0;32m   1214\u001b[0m     \u001b[39mlambda\u001b[39;00m x: tf\u001b[39m.\u001b[39mreshape(x, ps\u001b[39m.\u001b[39mconcat([sample_shape, ps\u001b[39m.\u001b[39mshape(x)[\u001b[39m1\u001b[39m:]], \u001b[39m0\u001b[39m)),\n\u001b[0;32m   1215\u001b[0m     samples)\n\u001b[0;32m   1216\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_sample_static_shape(samples, sample_shape)\n",
      "File \u001b[1;32md:\\CONDA\\envs\\tfproba\\lib\\site-packages\\tensorflow_probability\\python\\distributions\\uniform.py:154\u001b[0m, in \u001b[0;36mUniform._sample_n\u001b[1;34m(self, n, seed)\u001b[0m\n\u001b[0;32m    152\u001b[0m low \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mconvert_to_tensor(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlow)\n\u001b[0;32m    153\u001b[0m high \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mconvert_to_tensor(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhigh)\n\u001b[1;32m--> 154\u001b[0m shape \u001b[39m=\u001b[39m ps\u001b[39m.\u001b[39mconcat([[n], \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_batch_shape_tensor(\n\u001b[0;32m    155\u001b[0m     low\u001b[39m=\u001b[39;49mlow, high\u001b[39m=\u001b[39;49mhigh)], \u001b[39m0\u001b[39m)\n\u001b[0;32m    156\u001b[0m samples \u001b[39m=\u001b[39m samplers\u001b[39m.\u001b[39muniform(shape\u001b[39m=\u001b[39mshape, dtype\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdtype, seed\u001b[39m=\u001b[39mseed)\n\u001b[0;32m    157\u001b[0m \u001b[39mreturn\u001b[39;00m low \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_range(low\u001b[39m=\u001b[39mlow, high\u001b[39m=\u001b[39mhigh) \u001b[39m*\u001b[39m samples\n",
      "File \u001b[1;32md:\\CONDA\\envs\\tfproba\\lib\\site-packages\\tensorflow_probability\\python\\distributions\\distribution.py:1013\u001b[0m, in \u001b[0;36mDistribution._batch_shape_tensor\u001b[1;34m(self, **parameter_kwargs)\u001b[0m\n\u001b[0;32m    986\u001b[0m \u001b[39m\"\"\"Infers batch shape from parameters.\u001b[39;00m\n\u001b[0;32m    987\u001b[0m \n\u001b[0;32m    988\u001b[0m \u001b[39mThe overall batch shape is inferred by broadcasting the batch shapes of\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1010\u001b[0m \u001b[39m  batch_shape_tensor: `Tensor` broadcast batch shape of all parameters.\u001b[39;00m\n\u001b[0;32m   1011\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1012\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1013\u001b[0m   \u001b[39mreturn\u001b[39;00m batch_shape_lib\u001b[39m.\u001b[39minferred_batch_shape_tensor(\n\u001b[0;32m   1014\u001b[0m       \u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparameter_kwargs)\n\u001b[0;32m   1015\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m:\n\u001b[0;32m   1016\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mCannot compute batch shape of distribution \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   1017\u001b[0m                             \u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m: you must implement at least one of \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   1018\u001b[0m                             \u001b[39m'\u001b[39m\u001b[39m`_batch_shape_tensor` or \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   1019\u001b[0m                             \u001b[39m'\u001b[39m\u001b[39m`_parameter_properties`.\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39m))\n",
      "File \u001b[1;32md:\\CONDA\\envs\\tfproba\\lib\\site-packages\\tensorflow_probability\\python\\internal\\batch_shape_lib.py:110\u001b[0m, in \u001b[0;36minferred_batch_shape_tensor\u001b[1;34m(batch_object, bijector_x_event_ndims, **parameter_kwargs)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minferred_batch_shape_tensor\u001b[39m(batch_object,\n\u001b[0;32m     79\u001b[0m                                 bijector_x_event_ndims\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m     80\u001b[0m                                 \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparameter_kwargs):\n\u001b[0;32m     81\u001b[0m   \u001b[39m\"\"\"Infers an object's batch shape from its  parameters.\u001b[39;00m\n\u001b[0;32m     82\u001b[0m \n\u001b[0;32m     83\u001b[0m \u001b[39m  Each parameter contributes a batch shape of\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[39m    batch_shape_tensor: `Tensor` broadcast batch shape of all parameters.\u001b[39;00m\n\u001b[0;32m    109\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 110\u001b[0m   batch_shapes \u001b[39m=\u001b[39m map_fn_over_parameters_with_event_ndims(\n\u001b[0;32m    111\u001b[0m       batch_object,\n\u001b[0;32m    112\u001b[0m       get_batch_shape_tensor_part,\n\u001b[0;32m    113\u001b[0m       bijector_x_event_ndims\u001b[39m=\u001b[39mbijector_x_event_ndims,\n\u001b[0;32m    114\u001b[0m       require_static\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    115\u001b[0m       \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparameter_kwargs)\n\u001b[0;32m    116\u001b[0m   \u001b[39mreturn\u001b[39;00m functools\u001b[39m.\u001b[39mreduce(ps\u001b[39m.\u001b[39mbroadcast_shape, tf\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mflatten(batch_shapes), [])\n",
      "File \u001b[1;32md:\\CONDA\\envs\\tfproba\\lib\\site-packages\\tensorflow_probability\\python\\internal\\batch_shape_lib.py:365\u001b[0m, in \u001b[0;36mmap_fn_over_parameters_with_event_ndims\u001b[1;34m(batch_object, fn, bijector_x_event_ndims, require_static, **parameter_kwargs)\u001b[0m\n\u001b[0;32m    359\u001b[0m     \u001b[39melif\u001b[39;00m (properties\u001b[39m.\u001b[39mis_tensor\n\u001b[0;32m    360\u001b[0m           \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m tf\u001b[39m.\u001b[39mis_tensor(param)\n\u001b[0;32m    361\u001b[0m           \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m tf\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mis_nested(param_event_ndims)):\n\u001b[0;32m    362\u001b[0m       \u001b[39m# As a last resort, try an explicit conversion.\u001b[39;00m\n\u001b[0;32m    363\u001b[0m       param \u001b[39m=\u001b[39m tensor_util\u001b[39m.\u001b[39mconvert_nonref_to_tensor(param, name\u001b[39m=\u001b[39mparam_name)\n\u001b[1;32m--> 365\u001b[0m   results[param_name] \u001b[39m=\u001b[39m nest\u001b[39m.\u001b[39;49mmap_structure_up_to(\n\u001b[0;32m    366\u001b[0m       param, fn, param, param_event_ndims)\n\u001b[0;32m    367\u001b[0m \u001b[39mreturn\u001b[39;00m results\n",
      "File \u001b[1;32md:\\CONDA\\envs\\tfproba\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:1427\u001b[0m, in \u001b[0;36mmap_structure_up_to\u001b[1;34m(shallow_tree, func, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m   1353\u001b[0m \u001b[39m@tf_export\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m__internal__.nest.map_structure_up_to\u001b[39m\u001b[39m\"\u001b[39m, v1\u001b[39m=\u001b[39m[])\n\u001b[0;32m   1354\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmap_structure_up_to\u001b[39m(shallow_tree, func, \u001b[39m*\u001b[39minputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m   1355\u001b[0m   \u001b[39m\"\"\"Applies a function or op to a number of partially flattened inputs.\u001b[39;00m\n\u001b[0;32m   1356\u001b[0m \n\u001b[0;32m   1357\u001b[0m \u001b[39m  The `inputs` are flattened up to `shallow_tree` before being mapped.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1425\u001b[0m \u001b[39m    `shallow_tree`.\u001b[39;00m\n\u001b[0;32m   1426\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1427\u001b[0m   \u001b[39mreturn\u001b[39;00m map_structure_with_tuple_paths_up_to(\n\u001b[0;32m   1428\u001b[0m       shallow_tree,\n\u001b[0;32m   1429\u001b[0m       \u001b[39mlambda\u001b[39;00m _, \u001b[39m*\u001b[39mvalues: func(\u001b[39m*\u001b[39mvalues),  \u001b[39m# Discards the path arg.\u001b[39;00m\n\u001b[0;32m   1430\u001b[0m       \u001b[39m*\u001b[39minputs,\n\u001b[0;32m   1431\u001b[0m       \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\CONDA\\envs\\tfproba\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:1527\u001b[0m, in \u001b[0;36mmap_structure_with_tuple_paths_up_to\u001b[1;34m(shallow_tree, func, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m   1518\u001b[0m flat_value_gen \u001b[39m=\u001b[39m (\n\u001b[0;32m   1519\u001b[0m     flatten_up_to(  \u001b[39m# pylint: disable=g-complex-comprehension\u001b[39;00m\n\u001b[0;32m   1520\u001b[0m         shallow_tree,\n\u001b[0;32m   1521\u001b[0m         input_tree,\n\u001b[0;32m   1522\u001b[0m         check_types,\n\u001b[0;32m   1523\u001b[0m         expand_composites\u001b[39m=\u001b[39mexpand_composites) \u001b[39mfor\u001b[39;00m input_tree \u001b[39min\u001b[39;00m inputs)\n\u001b[0;32m   1524\u001b[0m flat_path_gen \u001b[39m=\u001b[39m (\n\u001b[0;32m   1525\u001b[0m     path\n\u001b[0;32m   1526\u001b[0m     \u001b[39mfor\u001b[39;00m path, _ \u001b[39min\u001b[39;00m _yield_flat_up_to(shallow_tree, inputs[\u001b[39m0\u001b[39m], is_nested_fn))\n\u001b[1;32m-> 1527\u001b[0m results \u001b[39m=\u001b[39m [\n\u001b[0;32m   1528\u001b[0m     func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39mfor\u001b[39;00m args \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(flat_path_gen, \u001b[39m*\u001b[39mflat_value_gen)\n\u001b[0;32m   1529\u001b[0m ]\n\u001b[0;32m   1530\u001b[0m \u001b[39mreturn\u001b[39;00m pack_sequence_as(structure\u001b[39m=\u001b[39mshallow_tree, flat_sequence\u001b[39m=\u001b[39mresults,\n\u001b[0;32m   1531\u001b[0m                         expand_composites\u001b[39m=\u001b[39mexpand_composites)\n",
      "File \u001b[1;32md:\\CONDA\\envs\\tfproba\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:1528\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1518\u001b[0m flat_value_gen \u001b[39m=\u001b[39m (\n\u001b[0;32m   1519\u001b[0m     flatten_up_to(  \u001b[39m# pylint: disable=g-complex-comprehension\u001b[39;00m\n\u001b[0;32m   1520\u001b[0m         shallow_tree,\n\u001b[0;32m   1521\u001b[0m         input_tree,\n\u001b[0;32m   1522\u001b[0m         check_types,\n\u001b[0;32m   1523\u001b[0m         expand_composites\u001b[39m=\u001b[39mexpand_composites) \u001b[39mfor\u001b[39;00m input_tree \u001b[39min\u001b[39;00m inputs)\n\u001b[0;32m   1524\u001b[0m flat_path_gen \u001b[39m=\u001b[39m (\n\u001b[0;32m   1525\u001b[0m     path\n\u001b[0;32m   1526\u001b[0m     \u001b[39mfor\u001b[39;00m path, _ \u001b[39min\u001b[39;00m _yield_flat_up_to(shallow_tree, inputs[\u001b[39m0\u001b[39m], is_nested_fn))\n\u001b[0;32m   1527\u001b[0m results \u001b[39m=\u001b[39m [\n\u001b[1;32m-> 1528\u001b[0m     func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39mfor\u001b[39;00m args \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(flat_path_gen, \u001b[39m*\u001b[39mflat_value_gen)\n\u001b[0;32m   1529\u001b[0m ]\n\u001b[0;32m   1530\u001b[0m \u001b[39mreturn\u001b[39;00m pack_sequence_as(structure\u001b[39m=\u001b[39mshallow_tree, flat_sequence\u001b[39m=\u001b[39mresults,\n\u001b[0;32m   1531\u001b[0m                         expand_composites\u001b[39m=\u001b[39mexpand_composites)\n",
      "File \u001b[1;32md:\\CONDA\\envs\\tfproba\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:1429\u001b[0m, in \u001b[0;36mmap_structure_up_to.<locals>.<lambda>\u001b[1;34m(_, *values)\u001b[0m\n\u001b[0;32m   1353\u001b[0m \u001b[39m@tf_export\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m__internal__.nest.map_structure_up_to\u001b[39m\u001b[39m\"\u001b[39m, v1\u001b[39m=\u001b[39m[])\n\u001b[0;32m   1354\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmap_structure_up_to\u001b[39m(shallow_tree, func, \u001b[39m*\u001b[39minputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m   1355\u001b[0m   \u001b[39m\"\"\"Applies a function or op to a number of partially flattened inputs.\u001b[39;00m\n\u001b[0;32m   1356\u001b[0m \n\u001b[0;32m   1357\u001b[0m \u001b[39m  The `inputs` are flattened up to `shallow_tree` before being mapped.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1425\u001b[0m \u001b[39m    `shallow_tree`.\u001b[39;00m\n\u001b[0;32m   1426\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m   1427\u001b[0m   \u001b[39mreturn\u001b[39;00m map_structure_with_tuple_paths_up_to(\n\u001b[0;32m   1428\u001b[0m       shallow_tree,\n\u001b[1;32m-> 1429\u001b[0m       \u001b[39mlambda\u001b[39;00m _, \u001b[39m*\u001b[39mvalues: func(\u001b[39m*\u001b[39;49mvalues),  \u001b[39m# Discards the path arg.\u001b[39;00m\n\u001b[0;32m   1430\u001b[0m       \u001b[39m*\u001b[39minputs,\n\u001b[0;32m   1431\u001b[0m       \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\CONDA\\envs\\tfproba\\lib\\site-packages\\tensorflow_probability\\python\\internal\\batch_shape_lib.py:139\u001b[0m, in \u001b[0;36mget_batch_shape_tensor_part\u001b[1;34m(x, event_ndims)\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    138\u001b[0m   base_shape \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mshape(x)\n\u001b[1;32m--> 139\u001b[0m \u001b[39mreturn\u001b[39;00m _truncate_shape_tensor(base_shape, event_ndims)\n",
      "File \u001b[1;32md:\\CONDA\\envs\\tfproba\\lib\\site-packages\\tensorflow_probability\\python\\internal\\batch_shape_lib.py:179\u001b[0m, in \u001b[0;36m_truncate_shape_tensor\u001b[1;34m(shape, rightmost_ndims_to_truncate)\u001b[0m\n\u001b[0;32m    176\u001b[0m shape \u001b[39m=\u001b[39m ps\u001b[39m.\u001b[39mconvert_to_shape_tensor(shape, dtype_hint\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mint32)\n\u001b[0;32m    177\u001b[0m rightmost_ndims_to_truncate \u001b[39m=\u001b[39m ps\u001b[39m.\u001b[39mconvert_to_shape_tensor(\n\u001b[0;32m    178\u001b[0m     rightmost_ndims_to_truncate, dtype_hint\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mint32)\n\u001b[1;32m--> 179\u001b[0m base_rank \u001b[39m=\u001b[39m ps\u001b[39m.\u001b[39;49mrank_from_shape(shape)\n\u001b[0;32m    180\u001b[0m \u001b[39mreturn\u001b[39;00m shape[:(\n\u001b[0;32m    181\u001b[0m     base_rank \u001b[39m-\u001b[39m\n\u001b[0;32m    182\u001b[0m     \u001b[39m# Don't try to slice away more ndims than the parameter\u001b[39;00m\n\u001b[0;32m    183\u001b[0m     \u001b[39m# actually has, if that's fewer than `event_ndims` (i.e.,\u001b[39;00m\n\u001b[0;32m    184\u001b[0m     \u001b[39m# if it relies on broadcasting).\u001b[39;00m\n\u001b[0;32m    185\u001b[0m     ps\u001b[39m.\u001b[39mminimum(rightmost_ndims_to_truncate, base_rank))]\n",
      "File \u001b[1;32md:\\CONDA\\envs\\tfproba\\lib\\site-packages\\tensorflow_probability\\python\\internal\\prefer_static.py:193\u001b[0m, in \u001b[0;36mrank_from_shape\u001b[1;34m(shape_tensor_fn, tensorshape)\u001b[0m\n\u001b[0;32m    190\u001b[0m \u001b[39mif\u001b[39;00m tensorshape \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    191\u001b[0m   shape_tensor \u001b[39m=\u001b[39m (shape_tensor_fn() \u001b[39mif\u001b[39;00m callable(shape_tensor_fn)\n\u001b[0;32m    192\u001b[0m                   \u001b[39melse\u001b[39;00m shape_tensor_fn)\n\u001b[1;32m--> 193\u001b[0m   shape_tensor_ \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mget_static_value(shape_tensor)\n\u001b[0;32m    194\u001b[0m   \u001b[39mif\u001b[39;00m shape_tensor_ \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    195\u001b[0m     shape_tensor \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mint32(shape_tensor_)\n",
      "File \u001b[1;32md:\\CONDA\\envs\\tfproba\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_util.py:869\u001b[0m, in \u001b[0;36mconstant_value\u001b[1;34m(tensor, partial)\u001b[0m\n\u001b[0;32m    867\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(tensor, ops\u001b[39m.\u001b[39mEagerTensor):\n\u001b[0;32m    868\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 869\u001b[0m     \u001b[39mreturn\u001b[39;00m tensor\u001b[39m.\u001b[39;49mnumpy()\n\u001b[0;32m    870\u001b[0m   \u001b[39mexcept\u001b[39;00m errors_impl\u001b[39m.\u001b[39mUnimplementedError:\n\u001b[0;32m    871\u001b[0m     \u001b[39m# Some EagerTensors may not implement .numpy/resolve, e.g. parallel\u001b[39;00m\n\u001b[0;32m    872\u001b[0m     \u001b[39m# tensors with multiple components on different devices.\u001b[39;00m\n\u001b[0;32m    873\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32md:\\CONDA\\envs\\tfproba\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1159\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1136\u001b[0m \u001b[39m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[0;32m   1137\u001b[0m \n\u001b[0;32m   1138\u001b[0m \u001b[39mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1156\u001b[0m \u001b[39m    NumPy dtype.\u001b[39;00m\n\u001b[0;32m   1157\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1158\u001b[0m \u001b[39m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[1;32m-> 1159\u001b[0m maybe_arr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_numpy()  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1160\u001b[0m \u001b[39mreturn\u001b[39;00m maybe_arr\u001b[39m.\u001b[39mcopy() \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(maybe_arr, np\u001b[39m.\u001b[39mndarray) \u001b[39melse\u001b[39;00m maybe_arr\n",
      "File \u001b[1;32md:\\CONDA\\envs\\tfproba\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1125\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1123\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_numpy\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m   1124\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1125\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_numpy_internal()\n\u001b[0;32m   1126\u001b[0m   \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m     \u001b[39mraise\u001b[39;00m core\u001b[39m.\u001b[39m_status_to_exception(e) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print('Training Model for {} epochs'.format(EPOCHS))\n",
    "\n",
    "results = Result(defaultdict(list), {}, defaultdict(list), defaultdict(list))\n",
    "\n",
    "train_acc_metric = tfk.metrics.SparseCategoricalAccuracy()\n",
    "val_acc_metric = tfk.metrics.SparseCategoricalAccuracy()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print('Epoch {}...'.format(epoch))\n",
    "    for step, (x_batch, y_batch) in enumerate(train_set): \n",
    "        with tf.GradientTape() as tape:\n",
    "            pred = model(x_batch)\n",
    "            loss_value = loss_fn(y_batch, pred)\n",
    "        results.history[epoch].append(loss_value)\n",
    "        grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "        optim.apply_gradients(zip(grads, model.trainable_weights))\n",
    "\n",
    "        train_acc_metric.update_state(y_batch, pred)\n",
    "\n",
    "    train_acc = train_acc_metric.result()\n",
    "    results.acc_score[epoch].append(train_acc)\n",
    "    print(\"Training acc over epoch: %.4f\" % (float(train_acc),))\n",
    "\n",
    "    train_acc_metric.reset_states()\n",
    "\n",
    "    if step % BATCH_SIZE == 0:\n",
    "        print(\n",
    "            \"Training loss (for one batch) at step %d: %.4f\"\n",
    "            % (step, float(loss_value))\n",
    "        )\n",
    "\n",
    "    for x_batch, y_batch in val_set:\n",
    "        val_pred = model(x_batch, training=False)\n",
    "        val_acc_metric.update_state(y_batch, val_pred)\n",
    "    val_acc = val_acc_metric.result()\n",
    "    results.val_acc_score[epoch] = val_acc\n",
    "    val_acc_metric.reset_states()\n",
    "\n",
    "test_acc_metric = tfk.metrics.SparseCategoricalAccuracy()\n",
    "\n",
    "for x_batch, y_batch in test_set:\n",
    "    test_pred = model(x_batch, training=False)\n",
    "    test_acc_metric.update_state(y_batch, test_pred)\n",
    "test_acc = test_acc_metric.result()\n",
    "results.test_acc = test_acc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('tfproba')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "436b4fcf59259da6dc58e7cba2c0763a6ef61d3e8a386de76ee8b72546013833"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
