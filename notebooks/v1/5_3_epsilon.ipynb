{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import logging\n",
    "from pathlib import Path, PurePath\n",
    "from collections import defaultdict\n",
    "from src.models.lstm_based.base_model import epsilon_3_model, epsilon_5_model\n",
    "\n",
    "from src.models.structures import *\n",
    "from src.models.intermediate_robust_generator.model import *\n",
    "from src.models.lstm_based.helper import retrieve_dataset, aggregate\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as tfk\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "import sklearn as sk\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER = 2048\n",
    "BATCH_SIZE = 16\n",
    "LEARNING_RATE = 0.0001\n",
    "EPOCHS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_GEN = 3\n",
    "DATA_PATH = \"\"\n",
    "DATASET = 'MNIST'\n",
    "PARTITIONS = 1000\n",
    "PARTITION_DIR = \"D:\\SUMMER_2022\\PROJECT\\PredictionsFromAggregations\\data\\interim\\lstm\"\n",
    "MODEL_STORE = \"D:\\SUMMER_2022\\PROJECT\\PredictionsFromAggregations\\models\\v1\"\n",
    "SEED = 8008"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "name, data = retrieve_dataset(DATASET, None)\n",
    "x_train, x_test, y_train, y_test = data\n",
    "dataset = Dataset(name, x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean, shape, dataset = aggregate(dataset, PARTITIONS, PARTITION_DIR, SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(shape) == 3:\n",
    "    a, b, c = shape\n",
    "    d = 1\n",
    "else:\n",
    "    a, b, c, d = shape\n",
    "\n",
    "n_classes = len(np.unique(dataset.y_train))\n",
    "\n",
    "\n",
    "if len(dataset.x_train.shape) == 3:\n",
    "    x_train = np.expand_dims(dataset.x_train, axis=-1)\n",
    "    x_test = np.expand_dims(dataset.x_test, axis=-1)\n",
    "else:\n",
    "    x_train = dataset.x_train\n",
    "    x_test = dataset.x_test\n",
    "y_train = tfk.utils.to_categorical(dataset.y_train, n_classes)\n",
    "y_test = tfk.utils.to_categorical(dataset.y_test, n_classes)\n",
    "\n",
    "x_train, x_val, y_train, y_val = sk.model_selection.train_test_split(x_train, y_train, test_size=0.1, random_state=42)\n",
    "\"\"\"I present the current worst function in the codebase\"\"\"\n",
    "tf_convert = lambda x, y, types : (tf.data.Dataset.from_tensor_slices((tf.cast(x, types[0]), tf.cast(y, types[1])))).shuffle(BUFFER).batch(BATCH_SIZE, drop_remainder=True).cache().prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "train_set = tf_convert(x_train, y_train, [tf.float32, tf.uint8])\n",
    "test_set = tf_convert(x_test, y_test, [tf.float32, tf.uint8])\n",
    "val_set = tf_convert(x_val, y_val, [tf.float32, tf.uint8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = generator_config(b*c*d, 10, n_classes, 4, None, None)\n",
    "models ={\n",
    "    3 : epsilon_3_model,\n",
    "    5 : epsilon_5_model\n",
    "}\n",
    "try:\n",
    "    model = models[N_GEN](config)\n",
    "except KeyError:\n",
    "    print(\"No model matched n_gen value: {}\".format(N_GEN))\n",
    "    exit\n",
    "\n",
    "optim = tfk.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
    "loss_fn = tfk.losses.CategoricalCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training Model for {} epochs'.format(EPOCHS))\n",
    "\n",
    "model.compile(optimizer=optim, loss=loss_fn, metrics=[tfk.metrics.categorical_accuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model for 1 epochs\n",
      "Epoch 0...\n",
      "(16, 10) (16, 10)\n",
      "(16, 10) (16, 10)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\SUMMER_2022\\PROJECT\\PredictionsFromAggregations\\notebooks\\v1\\5_3_epsilon.ipynb Cell 9\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/SUMMER_2022/PROJECT/PredictionsFromAggregations/notebooks/v1/5_3_epsilon.ipynb#ch0000007?line=9'>10</a>\u001b[0m \u001b[39mfor\u001b[39;00m step, (x_batch, y_batch) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_set): \n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/SUMMER_2022/PROJECT/PredictionsFromAggregations/notebooks/v1/5_3_epsilon.ipynb#ch0000007?line=10'>11</a>\u001b[0m     \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mGradientTape() \u001b[39mas\u001b[39;00m tape:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/SUMMER_2022/PROJECT/PredictionsFromAggregations/notebooks/v1/5_3_epsilon.ipynb#ch0000007?line=11'>12</a>\u001b[0m         pred \u001b[39m=\u001b[39m model(x_batch)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/SUMMER_2022/PROJECT/PredictionsFromAggregations/notebooks/v1/5_3_epsilon.ipynb#ch0000007?line=12'>13</a>\u001b[0m         loss_value \u001b[39m=\u001b[39m loss_fn(y_batch, pred)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/SUMMER_2022/PROJECT/PredictionsFromAggregations/notebooks/v1/5_3_epsilon.ipynb#ch0000007?line=13'>14</a>\u001b[0m     results\u001b[39m.\u001b[39mhistory[epoch]\u001b[39m.\u001b[39mappend(loss_value)\n",
      "File \u001b[1;32md:\\CONDA\\envs\\tfproba\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32md:\\CONDA\\envs\\tfproba\\lib\\site-packages\\keras\\engine\\training.py:490\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    486\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m(inputs, \u001b[39m*\u001b[39mcopied_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcopied_kwargs)\n\u001b[0;32m    488\u001b[0m   layout_map_lib\u001b[39m.\u001b[39m_map_subclass_model_variable(\u001b[39mself\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_layout_map)\n\u001b[1;32m--> 490\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\CONDA\\envs\\tfproba\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32md:\\CONDA\\envs\\tfproba\\lib\\site-packages\\keras\\engine\\base_layer.py:1014\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1010\u001b[0m   inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[0;32m   1012\u001b[0m \u001b[39mwith\u001b[39;00m autocast_variable\u001b[39m.\u001b[39menable_auto_cast_variables(\n\u001b[0;32m   1013\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_dtype_object):\n\u001b[1;32m-> 1014\u001b[0m   outputs \u001b[39m=\u001b[39m call_fn(inputs, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1016\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_activity_regularizer:\n\u001b[0;32m   1017\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[1;32md:\\CONDA\\envs\\tfproba\\lib\\site-packages\\keras\\utils\\traceback_utils.py:92\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     90\u001b[0m bound_signature \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     91\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 92\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     93\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     94\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m'\u001b[39m\u001b[39m_keras_call_info_injected\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m     95\u001b[0m     \u001b[39m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[1;32md:\\CONDA\\envs\\tfproba\\lib\\site-packages\\src-0.1.0-py3.9.egg\\src\\models\\lstm_based\\base_model.py:46\u001b[0m, in \u001b[0;36mepsilon_3_model.call\u001b[1;34m(self, input_tensor)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcall\u001b[39m(\u001b[39mself\u001b[39m, input_tensor):\n\u001b[1;32m---> 46\u001b[0m     gen1 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerator1(input_tensor)\n\u001b[0;32m     47\u001b[0m     gen2 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgenerator2(input_tensor)\n\u001b[0;32m     48\u001b[0m     gen3 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgenerator3(input_tensor)\n",
      "File \u001b[1;32md:\\CONDA\\envs\\tfproba\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32md:\\CONDA\\envs\\tfproba\\lib\\site-packages\\keras\\engine\\base_layer.py:1014\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1010\u001b[0m   inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[0;32m   1012\u001b[0m \u001b[39mwith\u001b[39;00m autocast_variable\u001b[39m.\u001b[39menable_auto_cast_variables(\n\u001b[0;32m   1013\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_dtype_object):\n\u001b[1;32m-> 1014\u001b[0m   outputs \u001b[39m=\u001b[39m call_fn(inputs, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1016\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_activity_regularizer:\n\u001b[0;32m   1017\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[1;32md:\\CONDA\\envs\\tfproba\\lib\\site-packages\\keras\\utils\\traceback_utils.py:92\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     90\u001b[0m bound_signature \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     91\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 92\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     93\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     94\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m'\u001b[39m\u001b[39m_keras_call_info_injected\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m     95\u001b[0m     \u001b[39m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[1;32md:\\CONDA\\envs\\tfproba\\lib\\site-packages\\src-0.1.0-py3.9.egg\\src\\models\\layers\\custom_layers.py:50\u001b[0m, in \u001b[0;36msingle_epsilon_generator.call\u001b[1;34m(self, input_tensor)\u001b[0m\n\u001b[0;32m     48\u001b[0m a, b, c, d \u001b[39m=\u001b[39m input_tensor\u001b[39m.\u001b[39mshape\n\u001b[0;32m     49\u001b[0m interim_tensor \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mreshape(input_tensor, [\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\n\u001b[1;32m---> 50\u001b[0m x \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mmap_fn(\u001b[39mlambda\u001b[39;49;00m x : \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_distr(x), elems\u001b[39m=\u001b[39;49minterim_tensor)\n\u001b[0;32m     51\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintermediate: \n\u001b[0;32m     52\u001b[0m     x \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mreshape(x, [a, b, c, d])\n",
      "File \u001b[1;32md:\\CONDA\\envs\\tfproba\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:629\u001b[0m, in \u001b[0;36mdeprecated_arg_values.<locals>.deprecated_wrapper.<locals>.new_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    622\u001b[0m           _PRINTED_WARNING[(func, arg_name)] \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    623\u001b[0m         logging\u001b[39m.\u001b[39mwarning(\n\u001b[0;32m    624\u001b[0m             \u001b[39m'\u001b[39m\u001b[39mFrom \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: calling \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m (from \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m) with \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m=\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m is deprecated and \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    625\u001b[0m             \u001b[39m'\u001b[39m\u001b[39mwill be removed \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mInstructions for updating:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m,\n\u001b[0;32m    626\u001b[0m             _call_location(), decorator_utils\u001b[39m.\u001b[39mget_qualified_name(func),\n\u001b[0;32m    627\u001b[0m             func\u001b[39m.\u001b[39m\u001b[39m__module__\u001b[39m, arg_name, arg_value, \u001b[39m'\u001b[39m\u001b[39min a future version\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    628\u001b[0m             \u001b[39mif\u001b[39;00m date \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m (\u001b[39m'\u001b[39m\u001b[39mafter \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m date), instructions)\n\u001b[1;32m--> 629\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\CONDA\\envs\\tfproba\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:561\u001b[0m, in \u001b[0;36mdeprecated_args.<locals>.deprecated_wrapper.<locals>.new_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    553\u001b[0m         _PRINTED_WARNING[(func, arg_name)] \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    554\u001b[0m       logging\u001b[39m.\u001b[39mwarning(\n\u001b[0;32m    555\u001b[0m           \u001b[39m'\u001b[39m\u001b[39mFrom \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: calling \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m (from \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m) with \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m is deprecated and will \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    556\u001b[0m           \u001b[39m'\u001b[39m\u001b[39mbe removed \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mInstructions for updating:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    559\u001b[0m           \u001b[39m'\u001b[39m\u001b[39min a future version\u001b[39m\u001b[39m'\u001b[39m \u001b[39mif\u001b[39;00m date \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m (\u001b[39m'\u001b[39m\u001b[39mafter \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m date),\n\u001b[0;32m    560\u001b[0m           instructions)\n\u001b[1;32m--> 561\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\CONDA\\envs\\tfproba\\lib\\site-packages\\tensorflow\\python\\ops\\map_fn.py:637\u001b[0m, in \u001b[0;36mmap_fn_v2\u001b[1;34m(fn, elems, dtype, parallel_iterations, back_prop, swap_memory, infer_shape, name, fn_output_signature)\u001b[0m\n\u001b[0;32m    635\u001b[0m \u001b[39mif\u001b[39;00m fn_output_signature \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    636\u001b[0m   fn_output_signature \u001b[39m=\u001b[39m dtype\n\u001b[1;32m--> 637\u001b[0m \u001b[39mreturn\u001b[39;00m map_fn(\n\u001b[0;32m    638\u001b[0m     fn\u001b[39m=\u001b[39;49mfn,\n\u001b[0;32m    639\u001b[0m     elems\u001b[39m=\u001b[39;49melems,\n\u001b[0;32m    640\u001b[0m     fn_output_signature\u001b[39m=\u001b[39;49mfn_output_signature,\n\u001b[0;32m    641\u001b[0m     parallel_iterations\u001b[39m=\u001b[39;49mparallel_iterations,\n\u001b[0;32m    642\u001b[0m     back_prop\u001b[39m=\u001b[39;49mback_prop,\n\u001b[0;32m    643\u001b[0m     swap_memory\u001b[39m=\u001b[39;49mswap_memory,\n\u001b[0;32m    644\u001b[0m     infer_shape\u001b[39m=\u001b[39;49minfer_shape,\n\u001b[0;32m    645\u001b[0m     name\u001b[39m=\u001b[39;49mname)\n",
      "File \u001b[1;32md:\\CONDA\\envs\\tfproba\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:561\u001b[0m, in \u001b[0;36mdeprecated_args.<locals>.deprecated_wrapper.<locals>.new_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    553\u001b[0m         _PRINTED_WARNING[(func, arg_name)] \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    554\u001b[0m       logging\u001b[39m.\u001b[39mwarning(\n\u001b[0;32m    555\u001b[0m           \u001b[39m'\u001b[39m\u001b[39mFrom \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: calling \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m (from \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m) with \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m is deprecated and will \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    556\u001b[0m           \u001b[39m'\u001b[39m\u001b[39mbe removed \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mInstructions for updating:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    559\u001b[0m           \u001b[39m'\u001b[39m\u001b[39min a future version\u001b[39m\u001b[39m'\u001b[39m \u001b[39mif\u001b[39;00m date \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m (\u001b[39m'\u001b[39m\u001b[39mafter \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m date),\n\u001b[0;32m    560\u001b[0m           instructions)\n\u001b[1;32m--> 561\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\CONDA\\envs\\tfproba\\lib\\site-packages\\tensorflow\\python\\ops\\map_fn.py:495\u001b[0m, in \u001b[0;36mmap_fn\u001b[1;34m(fn, elems, dtype, parallel_iterations, back_prop, swap_memory, infer_shape, name, fn_output_signature)\u001b[0m\n\u001b[0;32m    490\u001b[0m   tas \u001b[39m=\u001b[39m [\n\u001b[0;32m    491\u001b[0m       ta\u001b[39m.\u001b[39mwrite(i, value) \u001b[39mfor\u001b[39;00m (ta, value) \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(tas, result_value_batchable)\n\u001b[0;32m    492\u001b[0m   ]\n\u001b[0;32m    493\u001b[0m   \u001b[39mreturn\u001b[39;00m (i \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m, tas)\n\u001b[1;32m--> 495\u001b[0m _, r_a \u001b[39m=\u001b[39m control_flow_ops\u001b[39m.\u001b[39;49mwhile_loop(\n\u001b[0;32m    496\u001b[0m     \u001b[39mlambda\u001b[39;49;00m i, _: i \u001b[39m<\u001b[39;49m n,\n\u001b[0;32m    497\u001b[0m     compute, (i, result_batchable_ta),\n\u001b[0;32m    498\u001b[0m     parallel_iterations\u001b[39m=\u001b[39;49mparallel_iterations,\n\u001b[0;32m    499\u001b[0m     back_prop\u001b[39m=\u001b[39;49mback_prop,\n\u001b[0;32m    500\u001b[0m     swap_memory\u001b[39m=\u001b[39;49mswap_memory,\n\u001b[0;32m    501\u001b[0m     maximum_iterations\u001b[39m=\u001b[39;49mn)\n\u001b[0;32m    502\u001b[0m result_batchable \u001b[39m=\u001b[39m [r\u001b[39m.\u001b[39mstack() \u001b[39mfor\u001b[39;00m r \u001b[39min\u001b[39;00m r_a]\n\u001b[0;32m    504\u001b[0m \u001b[39m# Update each output tensor w/ static shape info about the outer dimension.\u001b[39;00m\n",
      "File \u001b[1;32md:\\CONDA\\envs\\tfproba\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py:2753\u001b[0m, in \u001b[0;36mwhile_loop\u001b[1;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\u001b[0m\n\u001b[0;32m   2749\u001b[0m packed \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m  \u001b[39m# whether the body result was packed into a 1-item tuple\u001b[39;00m\n\u001b[0;32m   2751\u001b[0m loop_var_structure \u001b[39m=\u001b[39m nest\u001b[39m.\u001b[39mmap_structure(type_spec\u001b[39m.\u001b[39mtype_spec_from_value,\n\u001b[0;32m   2752\u001b[0m                                         \u001b[39mlist\u001b[39m(loop_vars))\n\u001b[1;32m-> 2753\u001b[0m \u001b[39mwhile\u001b[39;00m cond(\u001b[39m*\u001b[39;49mloop_vars):\n\u001b[0;32m   2754\u001b[0m   loop_vars \u001b[39m=\u001b[39m body(\u001b[39m*\u001b[39mloop_vars)\n\u001b[0;32m   2755\u001b[0m   \u001b[39mif\u001b[39;00m try_to_pack \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(loop_vars, (\u001b[39mlist\u001b[39m, _basetuple)):\n",
      "File \u001b[1;32md:\\CONDA\\envs\\tfproba\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py:2744\u001b[0m, in \u001b[0;36mwhile_loop.<locals>.<lambda>\u001b[1;34m(i, lv)\u001b[0m\n\u001b[0;32m   2741\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   2742\u001b[0m   loop_vars \u001b[39m=\u001b[39m (counter, loop_vars)\n\u001b[0;32m   2743\u001b[0m   cond \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m i, lv: (  \u001b[39m# pylint: disable=g-long-lambda\u001b[39;00m\n\u001b[1;32m-> 2744\u001b[0m       math_ops\u001b[39m.\u001b[39;49mlogical_and(i \u001b[39m<\u001b[39;49m maximum_iterations, orig_cond(\u001b[39m*\u001b[39;49mlv)))\n\u001b[0;32m   2745\u001b[0m   body \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m i, lv: (i \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m, orig_body(\u001b[39m*\u001b[39mlv))\n\u001b[0;32m   2746\u001b[0m try_to_pack \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32md:\\CONDA\\envs\\tfproba\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py:5693\u001b[0m, in \u001b[0;36mlogical_and\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m   5691\u001b[0m \u001b[39mif\u001b[39;00m tld\u001b[39m.\u001b[39mis_eager:\n\u001b[0;32m   5692\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 5693\u001b[0m     _result \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_FastPathExecute(\n\u001b[0;32m   5694\u001b[0m       _ctx, \u001b[39m\"\u001b[39;49m\u001b[39mLogicalAnd\u001b[39;49m\u001b[39m\"\u001b[39;49m, name, x, y)\n\u001b[0;32m   5695\u001b[0m     \u001b[39mreturn\u001b[39;00m _result\n\u001b[0;32m   5696\u001b[0m   \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print('Training Model for {} epochs'.format(EPOCHS))\n",
    "\n",
    "results = Result(defaultdict(list), {}, defaultdict(list), defaultdict(list))\n",
    "\n",
    "train_acc_metric = tfk.metrics.CategoricalAccuracy()\n",
    "val_acc_metric = tfk.metrics.CategoricalAccuracy()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print('Epoch {}...'.format(epoch))\n",
    "    for step, (x_batch, y_batch) in enumerate(train_set): \n",
    "        with tf.GradientTape() as tape:\n",
    "            pred = model(x_batch)\n",
    "            loss_value = loss_fn(y_batch, pred)\n",
    "        results.history[epoch].append(loss_value)\n",
    "        grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "        optim.apply_gradients(zip(grads, model.trainable_weights))\n",
    "        train_acc_metric.update_state(y_batch, pred)\n",
    "\n",
    "    train_acc = train_acc_metric.result()\n",
    "    results.acc_score[epoch].append(train_acc)\n",
    "    print(\"Training acc over epoch: %.4f\" % (float(train_acc),))\n",
    "\n",
    "    train_acc_metric.reset_states()\n",
    "\n",
    "    if step % BATCH_SIZE == 0:\n",
    "        print(\n",
    "            \"Training loss (for one batch) at step %d: %.4f\"\n",
    "            % (step, float(loss_value))\n",
    "        )\n",
    "\n",
    "    for x_batch, y_batch in val_set:\n",
    "        val_pred = model(x_batch, training=False)\n",
    "        val_acc_metric.update_state(y_batch, val_pred)\n",
    "    val_acc = val_acc_metric.result()\n",
    "    results.val_acc_score[epoch] = val_acc\n",
    "    val_acc_metric.reset_states()\n",
    "\n",
    "test_acc_metric = tfk.metrics.CategoricalAccuracy()\n",
    "\n",
    "for x_batch, y_batch in test_set:\n",
    "    test_pred = model(x_batch, training=False)\n",
    "    test_acc_metric.update_state(y_batch, test_pred)\n",
    "test_acc = test_acc_metric.result()\n",
    "results.test_acc = test_acc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('tfproba')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "436b4fcf59259da6dc58e7cba2c0763a6ef61d3e8a386de76ee8b72546013833"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
